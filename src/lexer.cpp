#include <iostream>
#include <string>
#include <unordered_map>
#include <vector>
using namespace std;

enum class TokenType {
  IDENTIFIER,
  CONSTANT,
  INT_KEYWORD,
  VOID_KEYWORD,
  RETURN_KEYWORD,
  OPEN_PARENTHESIS,
  CLOSE_PARENTHESIS,
  OPEN_BRACE,
  CLOSE_BRACE,
  SEMICOLON,
  UNKNOWN
};

struct Token {
  TokenType type;
  string value;
  Token(TokenType t, const string& v) : type(t), value(v) {}
};

struct Lexer {
private:
  string input;
  size_t position;
  unordered_map<string, TokenType> keywords;

  void initKeywords() {
    keywords["int"] = TokenType::INT_KEYWORD;
    keywords["void"] = TokenType::VOID_KEYWORD;
    keywords["return"] = TokenType::RETURN_KEYWORD;
  }

  bool isWhiteSpace(char c) {
    return c == ' ' || c == '\t' || c == '\n' || c == '\r';
  }

  bool isAlpha(char c) {
    return (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z');
  }

  bool isDigit(char c) {
    return (c >= '0' && c <= '9');
  }

  bool isAlphaNumeric(char c) {
    return isAlpha(c) || isDigit(c);
  }

  string getNextWord() {
    size_t start = position;
    while (position < input.length() && isAlphaNumeric(input[position])) {
      position++;
    }
    return input.substr(start, position - start);
  }

  string getNextNumber() {
    size_t start = position;
    while (position < input.length() && isDigit(input[position])) {
      position++;
    }
    return input.substr(start, position - start);
  }

public:
  Lexer(const string& source) : input(source), position(0) {
    initKeywords();
  }

  vector<Token> tokenize() {
    vector<Token> tokens;

    while (position < input.length()) {
      char currentChar = input[position];

      if (isWhiteSpace(currentChar)) {
        position++;
        continue;
      }

      if (isAlpha(currentChar)) {
        string word = getNextWord();
        if (keywords.find(word) != keywords.end()) {
          tokens.emplace_back(keywords[word], word);
        } else {
          tokens.emplace_back(TokenType::IDENTIFIER, word);
        }
      }
      else if (isDigit(currentChar)) {
        string number = getNextNumber();
        tokens.emplace_back(TokenType::CONSTANT, number);
      }
      else if (currentChar == '(' || currentChar == ')' ||
               currentChar == '{' || currentChar == '}' ||
               currentChar == ';') {
        switch (currentChar) {
          case '(':
            tokens.emplace_back(TokenType::OPEN_PARENTHESIS, "(");
            break;
          case ')':
            tokens.emplace_back(TokenType::CLOSE_PARENTHESIS, ")");
            break;
          case '{':
            tokens.emplace_back(TokenType::OPEN_BRACE, "{");
            break;
          case '}':
            tokens.emplace_back(TokenType::CLOSE_BRACE, "}");
            break;
          case ';':
            tokens.emplace_back(TokenType::SEMICOLON, ";");
            break;
        }
        position++;
      }
      else {
        tokens.emplace_back(TokenType::UNKNOWN, string(1, currentChar));
        position++;
      }
    }

    return tokens;
  }
};

string getTokenTypeName(TokenType type) {
  switch (type) {
    case TokenType::IDENTIFIER: return "IDENTIFIER";
    case TokenType::CONSTANT: return "CONSTANT";
    case TokenType::INT_KEYWORD: return "INT_KEYWORD";
    case TokenType::VOID_KEYWORD: return "VOID_KEYWORD";
    case TokenType::RETURN_KEYWORD: return "RETURN_KEYWORD";
    case TokenType::OPEN_PARENTHESIS: return "OPEN_PARENTHESIS";
    case TokenType::CLOSE_PARENTHESIS: return "CLOSE_PARENTHESIS";
    case TokenType::OPEN_BRACE: return "OPEN_BRACE";
    case TokenType::CLOSE_BRACE: return "CLOSE_BRACE";
    case TokenType::SEMICOLON: return "SEMICOLON";
    case TokenType::UNKNOWN: return "UNKNOWN";
  }
  return "UNKNOWN";
}

void printTokens(const vector<Token>& tokens) {
  for (const auto& token : tokens) {
    cout << "Type: " << getTokenTypeName(token.type)
         << ", Value: " << token.value << endl;
  }
}

int main() {
  string sourceCode = "int main() { return 0; }";
  Lexer lexer(sourceCode);
  vector<Token> tokens = lexer.tokenize();

  cout << "Source code: " << sourceCode << endl << endl;
  cout << "Tokens Generated by Lexical Analyzer:" << endl;
  printTokens(tokens);

  return 0;
}
